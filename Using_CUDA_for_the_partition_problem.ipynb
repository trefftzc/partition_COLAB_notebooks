{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPpAXK9aRPR4UCohjO0BdPO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trefftzc/partition_COLAB_notebooks/blob/main/Using_CUDA_for_the_partition_problem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Yl5Wgx34oa6G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A small example of coding with CUDA\n",
        "CUDA is the programming language that NVIDIA created to program its GPUs.\n",
        "\n",
        "There are several key steps in programming a GPU:\n",
        "\n",
        "1. Allocating memory in the GPU card\n",
        "2. Copying data from the host memory to the GPU memory\n",
        "3. Executing code in the GPU\n",
        "4. Copying the results back to the host memory\n",
        "\n",
        "Before continuing, make sure that you have set the runtime environment to a GPU.\n",
        "\n",
        "Choose the Runtime set of commands on top and selecte\n",
        " Change runtime type\n",
        "\n",
        " Choose T4 GPU"
      ],
      "metadata": {
        "id": "tscICGBYocWe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The CUDA code needs a special compiler from NVIDIA called nvcc.\n",
        "nvcc is installed by default on COLAB."
      ],
      "metadata": {
        "id": "DBKCBAvCqFC8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1HE6NZIoZ7H",
        "outputId": "4ff9ec52-3200-439b-e6b7-ef69e856545c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you are interested in the specifications of the GPU, and you have an NVIDIA GPU on your system, the command nvidia-smi displays information about the GPU."
      ],
      "metadata": {
        "id": "5hn7z7I3qOyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-FFKGgwpexd",
        "outputId": "9afd1cbd-8b58-4545-ce35-247a6633903a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Oct  1 19:19:20 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the purpose of this example, we will see at an example that solves the partition problem."
      ],
      "metadata": {
        "id": "RTf6MdOkqxyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cudaPartition.cu\n",
        "/*\n",
        " * cudaPartition.cu\n",
        " * Solve the Partition problem using CUDA.\n",
        " * https://en.wikipedia.org/wiki/Partition_problem\n",
        " * This code works for multisets of up to 32 elements\n",
        " * The input is expected to be as follows:\n",
        " * The first line will contain n, the number of elements in the multiset\n",
        " * The remaining n lines will contain the n values, one per line\n",
        " */\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "// The kernel\n",
        "// This function is executed, in parallel, on the processors on the GPU card\n",
        "//\n",
        "__global__\n",
        "void evaluatePartition(  int n, int *array,int *result) {\n",
        "  unsigned int value = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "  int sum0s = 0;\n",
        "  int sum1s = 0;\n",
        "  unsigned int mask = 1;\n",
        "  for(int i = 0;i < n;i++) {\n",
        "    if ((mask & value) != 0) {\n",
        "      sum1s = sum1s + array[i];\n",
        "    }\n",
        "    else {\n",
        "      sum0s = sum0s + array[i];\n",
        "    }\n",
        "    mask = mask * 2;\n",
        "  }\n",
        "  if (sum0s == sum1s)\n",
        "     result[value] = 1;\n",
        "  else\n",
        "     result[value] = 0;\n",
        "  // printf(\"%d %d \\n\",value,result[value]);\n",
        "}\n",
        "\n",
        "void printResults(unsigned int value,int n,int *array)\n",
        "{\n",
        "  printf(\"Solution:\\n\");\n",
        "  printf(\"First partition: \") ;\n",
        "  unsigned int mask = 1;\n",
        "  int sum = 0;\n",
        "  for(int i = 0;i < n;i++) {\n",
        "    if ((mask & value) != 0) {\n",
        "      printf(\"%d \",array[i]);\n",
        "      sum = sum + array[i];\n",
        "    }\n",
        "    mask = mask * 2;\n",
        "  }\n",
        "  printf(\" sum: %d \\n\",sum);\n",
        "  printf(\"Second partition: \") ;\n",
        "  mask = 1;\n",
        "  sum = 0;\n",
        "  for(int i = 0;i < n;i++) {\n",
        "    if ((mask & value) == 0) {\n",
        "      printf(\"%d \",array[i]);\n",
        "      sum = sum + array[i];\n",
        "    }\n",
        "    mask = mask * 2;\n",
        "  }\n",
        "  printf(\" sum: %d \\n\",sum);\n",
        "}\n",
        "\n",
        "\n",
        "int main() {\n",
        "\n",
        "  int n;\n",
        "  int *array;\n",
        "\n",
        "  scanf(\"%d\",&n);\n",
        "\n",
        "  printf(\"The value of n is %d\\n\",n);\n",
        "  array = (int *) malloc (n * sizeof(int));\n",
        "  for(int i = 0;i < n;i++) {\n",
        "    scanf(\"%d\",&array[i]);\n",
        "  }\n",
        "  printf(\"The read values are: \\n\");\n",
        "  for(int i = 0;i < n;i++) {\n",
        "    printf(\"%d \",array[i]);\n",
        "  }\n",
        "  printf(\"\\n\");\n",
        "\n",
        "  unsigned int nPartitions = 1;\n",
        "  for(int i = 0;i < n;i++) {\n",
        "    nPartitions = nPartitions * 2;\n",
        "  }\n",
        "  // printf(\"The number of possible partitions is: %d\\n\",nPartitions);\n",
        "  // Only half of all possible partitions need be examined\n",
        "  // The second half is symmetrical to the first half\n",
        "  nPartitions = nPartitions / 2;\n",
        "\n",
        "  int solutionFound = 0;\n",
        "  int solution = -1;\n",
        "  // Allocate the variables in the device:\n",
        "  // The array with the integer values in the device is called d_array\n",
        "  int *d_array;\n",
        "  cudaMalloc(&d_array, n*sizeof(int));\n",
        "\n",
        "  // Copy the variables from the host to the device\n",
        "  cudaMemcpy(d_array,array,n*sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "  // Allocate on the device an array to keep all the results\n",
        "  int *d_results;\n",
        "  cudaMalloc(&d_results,nPartitions*sizeof(int));\n",
        "// Now invoke the kernel\n",
        "  evaluatePartition<<<(nPartitions+31)/32,32>>>(  n, d_array,d_results) ;\n",
        "  // The array on the host that will contain the results is called results\n",
        "  int *results;\n",
        "  results = (int *) calloc (nPartitions , sizeof(int));\n",
        "// Copy the results from the GPU card to main memory on the host\n",
        "  cudaMemcpy(results,d_results,nPartitions*sizeof(int),cudaMemcpyDeviceToHost);\n",
        "  /*\n",
        "  for(int i = 0;i < nPartitions;i++) {\n",
        "\t printf(\"%d \",results[i]);\n",
        "  }\n",
        "  printf(\"\\n\");\n",
        " */\n",
        "  for(int i = 0;i < nPartitions;i++) {\n",
        "\t  if (results[i] != 0) {\n",
        "\t\t  solutionFound = 1;\n",
        "\t\t  solution = i;\n",
        "\t\t  break;\n",
        "\t  }\n",
        "  }\n",
        "\n",
        "  if (solutionFound == 1) {\n",
        "    printResults(solution, n, array);\n",
        "  }\n",
        "  else {\n",
        "    printf(\"No solution was found.\");\n",
        "  }\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccmfoeLnrBDl",
        "outputId": "2a2f5259-6c57-41bc-b9e6-d963ecd46e3d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cudaPartition.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After writing the source code, we can compile it using the nvcc compiler."
      ],
      "metadata": {
        "id": "hVCYslsdrLxU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc cudaPartition.cu -o cudaPartition -O3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoEK6KYtrV_d",
        "outputId": "c8d5874c-c396-4ff4-bab0-5c560df84ebb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01mcudaPartition.cu(70)\u001b[0m: \u001b[01;35mwarning\u001b[0m #1650-D: result of call is not used\n",
            "    scanf(\"%d\",&n);\n",
            "    ^\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mcudaPartition.cu(75)\u001b[0m: \u001b[01;35mwarning\u001b[0m #1650-D: result of call is not used\n",
            "      scanf(\"%d\",&array[i]);\n",
            "      ^\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mcudaPartition.cu(70)\u001b[0m: \u001b[01;35mwarning\u001b[0m #1650-D: result of call is not used\n",
            "    scanf(\"%d\",&n);\n",
            "    ^\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mcudaPartition.cu(75)\u001b[0m: \u001b[01;35mwarning\u001b[0m #1650-D: result of call is not used\n",
            "      scanf(\"%d\",&array[i]);\n",
            "      ^\n",
            "\n",
            "\u001b[01m\u001b[KcudaPartition.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kint main()\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[KcudaPartition.cu:70:6:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kint scanf(const char*, ...)\u001b[m\u001b[K’ declared with attribute ‘\u001b[01m\u001b[Kwarn_unused_result\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-result\u0007-Wunused-result\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   70 | \u001b[01;35m\u001b[K  scanf(\"%d\",&n\u001b[m\u001b[K);\n",
            "      |   \u001b[01;35m\u001b[K~~~^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[KcudaPartition.cu:75:6:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kint scanf(const char*, ...)\u001b[m\u001b[K’ declared with attribute ‘\u001b[01m\u001b[Kwarn_unused_result\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-result\u0007-Wunused-result\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   75 | \u001b[01;35m\u001b[K    scanf(\"%d\",&array[i]\u001b[m\u001b[K);\n",
            "      |     \u001b[01;35m\u001b[K~^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a test file. This was used previously when testing the OpenMP code.\n"
      ],
      "metadata": {
        "id": "rIWnapo3rkM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile testNoSolution29.txt\n",
        "29\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "30\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hs84bi3JrqS8",
        "outputId": "0c096cf4-4439-4b4a-9249-702c10c996e6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing testNoSolution29.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now we can run and time the executable code on the GPU:"
      ],
      "metadata": {
        "id": "xdaLTj1XrySO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!time ./cudaPartition < testNoSolution29.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hH0P8mxRr2_0",
        "outputId": "149fa5be-167d-44fd-ba12-1c89c435f19c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The value of n is 29\n",
            "The read values are: \n",
            "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 30 \n",
            "No solution was found.\n",
            "real\t0m2.064s\n",
            "user\t0m0.781s\n",
            "sys\t0m1.053s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The key portions of the code are:\n",
        "1. Allocating variables in the memory of the GPU.\n",
        "\n",
        "This is done using the function\n",
        " cudaMalloc(&d_array, n*sizeof(int));\n",
        "\n",
        " This function has two parameters:\n",
        " - A pointer to a block of memory\n",
        " - The amount of memory that is needed"
      ],
      "metadata": {
        "id": "EvPgVlBEtFq9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step is to copy from the host memory to the GPU memory the content of the variables that will be used in the computation in the GPU. The function\n",
        "cudaMemcpy(d_array,array,n*sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "This function has four parameters:\n",
        "- The variable that will be receiving the result\n",
        "- The source of the copy\n",
        "- The amount of memory (in bytes) that will be copied\n",
        "- A constant that indicates the direction of the transfer. In this case we are copying from the host to the GPU (device)."
      ],
      "metadata": {
        "id": "nRrwp7CIts6s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step is to specify the code that will be executed on the GPU processors.\n",
        "\n",
        "Specifying the code to be executed on the GPU processors is where CUDA is different from regular C code.\n",
        "\n",
        "There are two main considerations:\n",
        "- Describing the code to be executed on each core on the GPU. To designate a particular function as code that will be executed on the GPU cores, CUDA uses two additional keywords __global__ (this indicates that this code can be called from the host ) and __device__ this indicates that this function can be called from another function executing on the GPU.\n",
        "\n",
        "The function will usually operate on entries on an array.\n",
        "It will be necessary to identify the entry on which this function will operate.\n",
        "This is usually achieved with a line like this:\n",
        "```\n",
        "\n",
        "unsigned int value = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "\n",
        "```\n",
        "The block size is chosen by the programmer.\n",
        "\n",
        "```\n",
        "\n",
        "__global__\n",
        "void evaluatePartition(  int n, int *array,int *result) {\n",
        "  unsigned int value = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "  int sum0s = 0;\n",
        "  int sum1s = 0;\n",
        "  unsigned int mask = 1;\n",
        "  for(int i = 0;i < n;i++) {\n",
        "    if ((mask & value) != 0) {\n",
        "      sum1s = sum1s + array[i];\n",
        "    }\n",
        "    else {\n",
        "      sum0s = sum0s + array[i];\n",
        "    }\n",
        "    mask = mask * 2;\n",
        "  }\n",
        "  if (sum0s == sum1s)\n",
        "     result[value] = 1;\n",
        "  else\n",
        "     result[value] = 0;\n",
        "  // printf(\"%d %d \\n\",value,result[value]);\n",
        "\n",
        "}\n",
        "```\n",
        "- The second consideration is how to call this function. NVIDIA introduced a new syntactic element into CUDA: Chevrons. Chevrons indicate that this function is meant to be executed on the GPU. Two values are passed between the Chevrons:\n",
        "```\n",
        " evaluatePartition<<<(nPartitions+31)/32,32>>>(  n, d_array,d_results) ;\n",
        "```\n",
        "The first parameter is the number of blocks that will be required for the execution of the program as an expression based on the size of the problem. Frequently, the size of the problem is the size of the array that will be operated upon. The second parameter is the block size."
      ],
      "metadata": {
        "id": "jtBUEeYWuakm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, the results are copied back to the host:\n",
        "\n",
        "```\n",
        "cudaMemcpy(results,d_results,nPartitions*sizeof(int),cudaMemcpyDeviceToHost);\n",
        "```\n",
        "\n",
        "The only change with respect to the previous usage of cudaMemcpy is the direction. Now one is copying from the GPU (device) to the host."
      ],
      "metadata": {
        "id": "ksl9ckp7dow8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create some additional test files so that we can observe how the execution times increase as the problem size grows.\n"
      ],
      "metadata": {
        "id": "zUHlbA5gg35T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test24.txt\n",
        "24\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "23"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUqWlL5vg-NS",
        "outputId": "87ad1268-ce03-49f0-e4e7-8afccf5e2dcc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting test24.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test25.txt\n",
        "25\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "24"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghuamEBmhGOb",
        "outputId": "4bfb4a6a-c2f0-44d4-d8cf-e736d9f1b7d3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting test25.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test26.txt\n",
        "26\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3ndmPfEhM6c",
        "outputId": "9e11e107-9e91-4548-d6a5-a816a3172ad6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting test26.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test27.txt\n",
        "27\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "26"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCbnXqhShV2j",
        "outputId": "bebdf45b-8b50-4c23-98a9-76c16ad9258d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting test27.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!time ./cudaPartition < test24.txt\n",
        "!time ./cudaPartition < test25.txt\n",
        "!time ./cudaPartition < test26.txt\n",
        "!time ./cudaPartition < test27.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zs44x78hYoD",
        "outputId": "6c09ca22-1c56-4b75-da19-c82536f4652e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The value of n is 24\n",
            "The read values are: \n",
            "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 23 \n",
            "Solution:\n",
            "First partition: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1  sum: 23 \n",
            "Second partition: 23  sum: 23 \n",
            "\n",
            "real\t0m0.328s\n",
            "user\t0m0.032s\n",
            "sys\t0m0.239s\n",
            "The value of n is 25\n",
            "The read values are: \n",
            "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 24 \n",
            "Solution:\n",
            "First partition: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1  sum: 24 \n",
            "Second partition: 24  sum: 24 \n",
            "\n",
            "real\t0m0.287s\n",
            "user\t0m0.046s\n",
            "sys\t0m0.235s\n",
            "The value of n is 26\n",
            "The read values are: \n",
            "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 25 \n",
            "Solution:\n",
            "First partition: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1  sum: 25 \n",
            "Second partition: 25  sum: 25 \n",
            "\n",
            "real\t0m0.372s\n",
            "user\t0m0.086s\n",
            "sys\t0m0.276s\n",
            "The value of n is 27\n",
            "The read values are: \n",
            "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 26 \n",
            "Solution:\n",
            "First partition: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1  sum: 26 \n",
            "Second partition: 26  sum: 26 \n",
            "\n",
            "real\t0m0.505s\n",
            "user\t0m0.156s\n",
            "sys\t0m0.337s\n"
          ]
        }
      ]
    }
  ]
}