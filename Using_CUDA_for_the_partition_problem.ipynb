{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPiM7j6HSv4B0RYYVR58JYV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trefftzc/partition_COLAB_notebooks/blob/main/Using_CUDA_for_the_partition_problem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Yl5Wgx34oa6G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A small example of coding with CUDA\n",
        "CUDA is the programming language that NVIDIA created to program its GPUs.\n",
        "\n",
        "There are several key steps in programming a GPU:\n",
        "\n",
        "1. Allocating memory in the GPU card\n",
        "2. Copying data from the host memory to the GPU memory\n",
        "3. Executing code in the GPU\n",
        "4. Copying the results back to the host memory\n",
        "\n",
        "Before continuing, make sure that you have set the runtime environment to a GPU.\n",
        "\n",
        "Choose the Runtime set of commands on top and selecte\n",
        " Change runtime type\n",
        "\n",
        " Choose T4 GPU"
      ],
      "metadata": {
        "id": "tscICGBYocWe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The CUDA code needs a special compiler from NVIDIA called nvcc.\n",
        "nvcc is installed by default on COLAB."
      ],
      "metadata": {
        "id": "DBKCBAvCqFC8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1HE6NZIoZ7H",
        "outputId": "b3603967-2366-4e62-a157-7904fecb3fed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you are interested in the specifications of the GPU, and you have an NVIDIA GPU on your system, the command nvidia-smi displays information about the GPU."
      ],
      "metadata": {
        "id": "5hn7z7I3qOyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-FFKGgwpexd",
        "outputId": "357d8992-5d50-4b60-e8b1-fa330555f51d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Oct  2 13:48:03 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   61C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the purpose of this example, we will see at an example that solves the partition problem."
      ],
      "metadata": {
        "id": "RTf6MdOkqxyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cudaPartition.cu\n",
        "/*\n",
        " * cudaPartition.cu\n",
        " * Solve the Partition problem using CUDA.\n",
        " * https://en.wikipedia.org/wiki/Partition_problem\n",
        " * This code works for multisets of up to 32 elements\n",
        " * The input is expected to be as follows:\n",
        " * The first line will contain n, the number of elements in the multiset\n",
        " * The remaining n lines will contain the n values, one per line\n",
        " */\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "// The kernel\n",
        "// This function is executed, in parallel, on the processors on the GPU card\n",
        "//\n",
        "__global__\n",
        "void evaluatePartition(  int n, int *array,int *result) {\n",
        "  unsigned int value = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "  int sum0s = 0;\n",
        "  int sum1s = 0;\n",
        "  unsigned int mask = 1;\n",
        "  for(int i = 0;i < n;i++) {\n",
        "    if ((mask & value) != 0) {\n",
        "      sum1s = sum1s + array[i];\n",
        "    }\n",
        "    else {\n",
        "      sum0s = sum0s + array[i];\n",
        "    }\n",
        "    mask = mask * 2;\n",
        "  }\n",
        "  if (sum0s == sum1s)\n",
        "     result[value] = 1;\n",
        "  else\n",
        "     result[value] = 0;\n",
        "  // printf(\"%d %d \\n\",value,result[value]);\n",
        "}\n",
        "\n",
        "void printResults(unsigned int value,int n,int *array)\n",
        "{\n",
        "  printf(\"Solution:\\n\");\n",
        "  printf(\"First partition: \") ;\n",
        "  unsigned int mask = 1;\n",
        "  int sum = 0;\n",
        "  for(int i = 0;i < n;i++) {\n",
        "    if ((mask & value) != 0) {\n",
        "      printf(\"%d \",array[i]);\n",
        "      sum = sum + array[i];\n",
        "    }\n",
        "    mask = mask * 2;\n",
        "  }\n",
        "  printf(\" sum: %d \\n\",sum);\n",
        "  printf(\"Second partition: \") ;\n",
        "  mask = 1;\n",
        "  sum = 0;\n",
        "  for(int i = 0;i < n;i++) {\n",
        "    if ((mask & value) == 0) {\n",
        "      printf(\"%d \",array[i]);\n",
        "      sum = sum + array[i];\n",
        "    }\n",
        "    mask = mask * 2;\n",
        "  }\n",
        "  printf(\" sum: %d \\n\",sum);\n",
        "}\n",
        "\n",
        "\n",
        "int main() {\n",
        "\n",
        "  int n;\n",
        "  int *array;\n",
        "\n",
        "  scanf(\"%d\",&n);\n",
        "\n",
        "  printf(\"The value of n is %d\\n\",n);\n",
        "  array = (int *) malloc (n * sizeof(int));\n",
        "  for(int i = 0;i < n;i++) {\n",
        "    scanf(\"%d\",&array[i]);\n",
        "  }\n",
        "  printf(\"The read values are: \\n\");\n",
        "  for(int i = 0;i < n;i++) {\n",
        "    printf(\"%d \",array[i]);\n",
        "  }\n",
        "  printf(\"\\n\");\n",
        "\n",
        "  unsigned int nPartitions = 1;\n",
        "  for(int i = 0;i < n;i++) {\n",
        "    nPartitions = nPartitions * 2;\n",
        "  }\n",
        "  // printf(\"The number of possible partitions is: %d\\n\",nPartitions);\n",
        "  // Only half of all possible partitions need be examined\n",
        "  // The second half is symmetrical to the first half\n",
        "  nPartitions = nPartitions / 2;\n",
        "\n",
        "  int solutionFound = 0;\n",
        "  int solution = -1;\n",
        "  // Allocate the variables in the device:\n",
        "  // The array with the integer values in the device is called d_array\n",
        "  int *d_array;\n",
        "  cudaMalloc(&d_array, n*sizeof(int));\n",
        "\n",
        "  // Copy the variables from the host to the device\n",
        "  cudaMemcpy(d_array,array,n*sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "  // Allocate on the device an array to keep all the results\n",
        "  int *d_results;\n",
        "  cudaMalloc(&d_results,nPartitions*sizeof(int));\n",
        "// Now invoke the kernel\n",
        "  evaluatePartition<<<(nPartitions+31)/32,32>>>(  n, d_array,d_results) ;\n",
        "  // The array on the host that will contain the results is called results\n",
        "  int *results;\n",
        "  results = (int *) calloc (nPartitions , sizeof(int));\n",
        "// Copy the results from the GPU card to main memory on the host\n",
        "  cudaMemcpy(results,d_results,nPartitions*sizeof(int),cudaMemcpyDeviceToHost);\n",
        "  /*\n",
        "  for(int i = 0;i < nPartitions;i++) {\n",
        "\t printf(\"%d \",results[i]);\n",
        "  }\n",
        "  printf(\"\\n\");\n",
        " */\n",
        "  for(int i = 0;i < nPartitions;i++) {\n",
        "\t  if (results[i] != 0) {\n",
        "\t\t  solutionFound = 1;\n",
        "\t\t  solution = i;\n",
        "\t\t  break;\n",
        "\t  }\n",
        "  }\n",
        "\n",
        "  if (solutionFound == 1) {\n",
        "    printResults(solution, n, array);\n",
        "  }\n",
        "  else {\n",
        "    printf(\"No solution was found.\");\n",
        "  }\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccmfoeLnrBDl",
        "outputId": "eda610ec-b4db-473e-de43-92d1ea06b92f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cudaPartition.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After writing the source code, we can compile it using the nvcc compiler."
      ],
      "metadata": {
        "id": "hVCYslsdrLxU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc cudaPartition.cu -o cudaPartition -O3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoEK6KYtrV_d",
        "outputId": "ac2f819c-c057-442f-c2b5-15bc3b7c9b92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01mcudaPartition.cu(70)\u001b[0m: \u001b[01;35mwarning\u001b[0m #1650-D: result of call is not used\n",
            "    scanf(\"%d\",&n);\n",
            "    ^\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mcudaPartition.cu(75)\u001b[0m: \u001b[01;35mwarning\u001b[0m #1650-D: result of call is not used\n",
            "      scanf(\"%d\",&array[i]);\n",
            "      ^\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mcudaPartition.cu(70)\u001b[0m: \u001b[01;35mwarning\u001b[0m #1650-D: result of call is not used\n",
            "    scanf(\"%d\",&n);\n",
            "    ^\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mcudaPartition.cu(75)\u001b[0m: \u001b[01;35mwarning\u001b[0m #1650-D: result of call is not used\n",
            "      scanf(\"%d\",&array[i]);\n",
            "      ^\n",
            "\n",
            "\u001b[01m\u001b[KcudaPartition.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kint main()\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[KcudaPartition.cu:70:6:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kint scanf(const char*, ...)\u001b[m\u001b[K’ declared with attribute ‘\u001b[01m\u001b[Kwarn_unused_result\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-result\u0007-Wunused-result\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   70 | \u001b[01;35m\u001b[K  scanf(\"%d\",&n\u001b[m\u001b[K);\n",
            "      |   \u001b[01;35m\u001b[K~~~^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[KcudaPartition.cu:75:6:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kint scanf(const char*, ...)\u001b[m\u001b[K’ declared with attribute ‘\u001b[01m\u001b[Kwarn_unused_result\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-result\u0007-Wunused-result\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   75 | \u001b[01;35m\u001b[K    scanf(\"%d\",&array[i]\u001b[m\u001b[K);\n",
            "      |     \u001b[01;35m\u001b[K~^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a test file. This was used previously when testing the OpenMP code.\n"
      ],
      "metadata": {
        "id": "rIWnapo3rkM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile testNoSolution29.txt\n",
        "29\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "30\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hs84bi3JrqS8",
        "outputId": "fd9f70d9-c8b9-4f36-ea1b-8fabd370b5b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing testNoSolution29.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now we can run and time the executable code on the GPU:"
      ],
      "metadata": {
        "id": "xdaLTj1XrySO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!time ./cudaPartition < testNoSolution29.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hH0P8mxRr2_0",
        "outputId": "40aa9704-b0c0-4911-ac72-ee5fe0bdf99a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The value of n is 29\n",
            "The read values are: \n",
            "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 30 \n",
            "No solution was found.\n",
            "real\t0m2.086s\n",
            "user\t0m0.754s\n",
            "sys\t0m0.936s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The key portions of the code are:\n",
        "1. Allocating variables in the memory of the GPU.\n",
        "\n",
        "This is done using the function\n",
        " cudaMalloc(&d_array, n*sizeof(int));\n",
        "\n",
        " This function has two parameters:\n",
        " - A pointer to a block of memory\n",
        " - The amount of memory that is needed"
      ],
      "metadata": {
        "id": "EvPgVlBEtFq9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step is to copy from the host memory to the GPU memory the content of the variables that will be used in the computation in the GPU. The function\n",
        "cudaMemcpy(d_array,array,n*sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "This function has four parameters:\n",
        "- The variable that will be receiving the result\n",
        "- The source of the copy\n",
        "- The amount of memory (in bytes) that will be copied\n",
        "- A constant that indicates the direction of the transfer. In this case we are copying from the host to the GPU (device)."
      ],
      "metadata": {
        "id": "nRrwp7CIts6s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step is to specify the code that will be executed on the GPU processors.\n",
        "\n",
        "Specifying the code to be executed on the GPU processors is where CUDA is different from regular C code.\n",
        "\n",
        "There are two main considerations:\n",
        "- Describing the code to be executed on each core on the GPU. To designate a particular function as code that will be executed on the GPU cores, CUDA uses two additional keywords __global__ (this indicates that this code can be called from the host ) and __device__ this indicates that this function can be called from another function executing on the GPU.\n",
        "\n",
        "The function will usually operate on entries on an array.\n",
        "It will be necessary to identify the entry on which this function will operate.\n",
        "This is usually achieved with a line like this:\n",
        "```\n",
        "\n",
        "unsigned int value = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "\n",
        "```\n",
        "The block size is chosen by the programmer.\n",
        "\n",
        "```\n",
        "\n",
        "__global__\n",
        "void evaluatePartition(  int n, int *array,int *result) {\n",
        "  unsigned int value = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "  int sum0s = 0;\n",
        "  int sum1s = 0;\n",
        "  unsigned int mask = 1;\n",
        "  for(int i = 0;i < n;i++) {\n",
        "    if ((mask & value) != 0) {\n",
        "      sum1s = sum1s + array[i];\n",
        "    }\n",
        "    else {\n",
        "      sum0s = sum0s + array[i];\n",
        "    }\n",
        "    mask = mask * 2;\n",
        "  }\n",
        "  if (sum0s == sum1s)\n",
        "     result[value] = 1;\n",
        "  else\n",
        "     result[value] = 0;\n",
        "  // printf(\"%d %d \\n\",value,result[value]);\n",
        "\n",
        "}\n",
        "```\n",
        "- The second consideration is how to call this function. NVIDIA introduced a new syntactic element into CUDA: Chevrons. Chevrons indicate that this function is meant to be executed on the GPU. Two values are passed between the Chevrons:\n",
        "```\n",
        " evaluatePartition<<<(nPartitions+31)/32,32>>>(  n, d_array,d_results) ;\n",
        "```\n",
        "The first parameter is the number of blocks that will be required for the execution of the program as an expression based on the size of the problem. Frequently, the size of the problem is the size of the array that will be operated upon. The second parameter is the block size."
      ],
      "metadata": {
        "id": "jtBUEeYWuakm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, the results are copied back to the host:\n",
        "\n",
        "```\n",
        "cudaMemcpy(results,d_results,nPartitions*sizeof(int),cudaMemcpyDeviceToHost);\n",
        "```\n",
        "\n",
        "The only change with respect to the previous usage of cudaMemcpy is the direction. Now one is copying from the GPU (device) to the host."
      ],
      "metadata": {
        "id": "ksl9ckp7dow8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create some additional test files so that we can observe how the execution times increase as the problem size grows.\n"
      ],
      "metadata": {
        "id": "zUHlbA5gg35T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test24.txt\n",
        "24\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "23"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUqWlL5vg-NS",
        "outputId": "9a75acee-4752-41a6-8038-390f524f035e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing test24.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test25.txt\n",
        "25\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "24"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghuamEBmhGOb",
        "outputId": "78bc3187-9e96-4e99-ed87-91748a0b0955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing test25.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test26.txt\n",
        "26\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3ndmPfEhM6c",
        "outputId": "8f37941c-f342-46af-a30c-fc2c57ae76b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing test26.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test27.txt\n",
        "27\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "1\n",
        "26"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCbnXqhShV2j",
        "outputId": "6c8d17c8-7372-489e-b88f-ae49486635e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing test27.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!time ./cudaPartition < test24.txt\n",
        "!time ./cudaPartition < test25.txt\n",
        "!time ./cudaPartition < test26.txt\n",
        "!time ./cudaPartition < test27.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zs44x78hYoD",
        "outputId": "6f307a47-7dab-4d33-8fa9-25b167e8a480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The value of n is 24\n",
            "The read values are: \n",
            "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 23 \n",
            "Solution:\n",
            "First partition: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1  sum: 23 \n",
            "Second partition: 23  sum: 23 \n",
            "\n",
            "real\t0m0.194s\n",
            "user\t0m0.037s\n",
            "sys\t0m0.143s\n",
            "The value of n is 25\n",
            "The read values are: \n",
            "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 24 \n",
            "Solution:\n",
            "First partition: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1  sum: 24 \n",
            "Second partition: 24  sum: 24 \n",
            "\n",
            "real\t0m0.232s\n",
            "user\t0m0.053s\n",
            "sys\t0m0.168s\n",
            "The value of n is 26\n",
            "The read values are: \n",
            "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 25 \n",
            "Solution:\n",
            "First partition: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1  sum: 25 \n",
            "Second partition: 25  sum: 25 \n",
            "\n",
            "real\t0m0.325s\n",
            "user\t0m0.101s\n",
            "sys\t0m0.204s\n",
            "The value of n is 27\n",
            "The read values are: \n",
            "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 26 \n",
            "Solution:\n",
            "First partition: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1  sum: 26 \n",
            "Second partition: 26  sum: 26 \n",
            "\n",
            "real\t0m0.525s\n",
            "user\t0m0.191s\n",
            "sys\t0m0.311s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Profiling the code\n",
        "NVIDA has created a profiler that can be used to find where the time is being spent during the execution of the program. The command is called nvprof."
      ],
      "metadata": {
        "id": "ps8lajSmgeUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./cudaPartition < test24.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNIndqg2fbaS",
        "outputId": "cb039e39-dcfc-4e2d-beb4-422fba90fcbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The value of n is 24\n",
            "The read values are: \n",
            "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 23 \n",
            "==1698== NVPROF is profiling process 1698, command: ./cudaPartition\n",
            "Solution:\n",
            "First partition: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1  sum: 23 \n",
            "Second partition: 23  sum: 23 \n",
            "==1698== Profiling application: ./cudaPartition\n",
            "==1698== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   96.55%  24.633ms         1  24.633ms  24.633ms  24.633ms  [CUDA memcpy DtoH]\n",
            "                    3.45%  879.44us         1  879.44us  879.44us  879.44us  evaluatePartition(int, int*, int*)\n",
            "                    0.00%  1.2160us         1  1.2160us  1.2160us  1.2160us  [CUDA memcpy HtoD]\n",
            "      API calls:   76.04%  87.504ms         2  43.752ms  118.86us  87.385ms  cudaMalloc\n",
            "                   23.64%  27.205ms         2  13.602ms  20.762us  27.184ms  cudaMemcpy\n",
            "                    0.17%  194.47us         1  194.47us  194.47us  194.47us  cudaLaunchKernel\n",
            "                    0.12%  139.82us       114  1.2260us     142ns  55.898us  cuDeviceGetAttribute\n",
            "                    0.01%  11.360us         1  11.360us  11.360us  11.360us  cuDeviceGetName\n",
            "                    0.01%  8.1350us         1  8.1350us  8.1350us  8.1350us  cuDeviceGetPCIBusId\n",
            "                    0.00%  4.5400us         1  4.5400us  4.5400us  4.5400us  cuDeviceTotalMem\n",
            "                    0.00%  1.3710us         3     457ns     202ns     931ns  cuDeviceGetCount\n",
            "                    0.00%     926ns         2     463ns     177ns     749ns  cuDeviceGet\n",
            "                    0.00%     547ns         1     547ns     547ns     547ns  cuModuleGetLoadingMode\n",
            "                    0.00%     234ns         1     234ns     234ns     234ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./cudaPartition < testNoSolution29.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEwQDEmGgKDi",
        "outputId": "5244b41a-5aa6-4659-c2c9-8da2617cdd2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The value of n is 29\n",
            "The read values are: \n",
            "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 30 \n",
            "==1950== NVPROF is profiling process 1950, command: ./cudaPartition\n",
            "No solution was found.==1950== Profiling application: ./cudaPartition\n",
            "==1950== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   96.91%  991.46ms         1  991.46ms  991.46ms  991.46ms  [CUDA memcpy DtoH]\n",
            "                    3.09%  31.642ms         1  31.642ms  31.642ms  31.642ms  evaluatePartition(int, int*, int*)\n",
            "                    0.00%  1.1840us         1  1.1840us  1.1840us  1.1840us  [CUDA memcpy HtoD]\n",
            "      API calls:   87.91%  1.02522s         2  512.61ms  25.490us  1.02520s  cudaMemcpy\n",
            "                   12.05%  140.50ms         2  70.251ms  1.7501ms  138.75ms  cudaMalloc\n",
            "                    0.02%  241.21us         1  241.21us  241.21us  241.21us  cudaLaunchKernel\n",
            "                    0.02%  192.37us       114  1.6870us     219ns  73.610us  cuDeviceGetAttribute\n",
            "                    0.00%  12.525us         1  12.525us  12.525us  12.525us  cuDeviceGetName\n",
            "                    0.00%  7.4280us         1  7.4280us  7.4280us  7.4280us  cuDeviceGetPCIBusId\n",
            "                    0.00%  6.1220us         1  6.1220us  6.1220us  6.1220us  cuDeviceTotalMem\n",
            "                    0.00%  1.9210us         3     640ns     301ns  1.2550us  cuDeviceGetCount\n",
            "                    0.00%  1.0100us         2     505ns     265ns     745ns  cuDeviceGet\n",
            "                    0.00%     534ns         1     534ns     534ns     534ns  cuModuleGetLoadingMode\n",
            "                    0.00%     375ns         1     375ns     375ns     375ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On the back of your summary of the readings for this week, fill the following form with the execution times:\n",
        "\n",
        "| File name  | Execution Time |\n",
        ":------------| -----------:|\n",
        "| test24.txt |  |\n",
        "| test25.txt |  |\n",
        "| test26.txt |  |\n",
        "| test27.txt |  |\n",
        "| testNoSolution29.txt |  |\n",
        "\n",
        "Look at the information provide by the profiler.\n",
        "Where is most of the execution time being spent?"
      ],
      "metadata": {
        "id": "PPuWx3x4jW9a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CGkTYS6Fjo6j"
      }
    }
  ]
}