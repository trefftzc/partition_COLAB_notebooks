{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPiOX5OZeqUNbbfWnfm+8hK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trefftzc/partition_COLAB_notebooks/blob/main/partition_numba_cuda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Partition with NUMBA/CUDA\n",
        "This python program is based on NUMBA/CUDA.\n",
        "It solves the partition problem.\n",
        "\n",
        "Make sure that COLAB has been set up to use a GPU.\n",
        "In the main menu select the option:\n",
        " Runtime\n",
        "In the pull-down menu select:\n",
        " Change runtime type\n",
        "Select:\n",
        " T4 GPU"
      ],
      "metadata": {
        "id": "TvlzT8w3e-P6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPU cards are dedicated computers with their own memory and their own processors.\n",
        "\n",
        "When programming a GPU, one needs to\n",
        "- allocate memory on the GPU card\n",
        "- copy data from the host's memory to the GPU's memory\n",
        "- execute the kernel, the code that is applied across all the elements of an array\n",
        "- copy the results of interest back to the host\n",
        "\n",
        "This is achieved in the code below in this portion of the code in the function\n",
        " parallelFor\n",
        "\n",
        "  arrayGPU = cuda.to_device(array)\n",
        "\n",
        "  resultGPU = cuda.to_device(result)\n",
        "  \n",
        "  evaluatePartition.forall(nPartitions)( arrayGPU,resultGPU, n)\n",
        "  \n",
        "  resultGPU.copy_to_host(result)\n",
        "\n",
        "One uses the decorator\n",
        " @cuda.jit\n",
        "to indicate to the numba/cuda compiler the code for the kernel.  \n",
        "\n"
      ],
      "metadata": {
        "id": "55bVlOe8hulr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KPmcXCre9UJ",
        "outputId": "b7622a98-888c-42cc-d757-838020bf3e0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing partition_numba_cuda.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile partition_numba_cuda.py\n",
        "#\n",
        "# Program that solves the partition problem in python\n",
        "# Parallel version with numba\n",
        "#\n",
        "import sys\n",
        "import numpy as np\n",
        "#import numba\n",
        "from numba import cuda\n",
        "from numba.cuda.cudadrv.devicearray import DeviceNDArray\n",
        "import time\n",
        "\n",
        "#\n",
        "# This is the kernel, the code that is executed in each processor\n",
        "# in the GPU\n",
        "#\n",
        "@cuda.jit\n",
        "def evaluatePartition(array:DeviceNDArray,result:DeviceNDArray,n:np.dtype=np.int64):\n",
        "   value = cuda.grid(1)\n",
        "   sum0s = 0\n",
        "   sum1s = 0\n",
        "   mask = 1\n",
        "   for i in range(0,n):\n",
        "    if ((mask & value) != 0):\n",
        "      sum1s = sum1s + array[i]\n",
        "    else:\n",
        "      sum0s = sum0s + array[i]\n",
        "    mask = mask * 2\n",
        "   if (sum0s == sum1s):\n",
        "     # print(\"Evaluate partition \",value,\" returns \",value)\n",
        "     result[value] = value\n",
        "   else:\n",
        "    # print(\"Evaluate partition \",value,\" returns \",0)\n",
        "    result[value] = 0\n",
        "\n",
        "def printResults(value, n, array):\n",
        "  print(\"Solution:\\n\")\n",
        "  print(\"First partition: \")\n",
        "  mask = 1\n",
        "  sum = 0\n",
        "  for i in range(0,n):\n",
        "    if ((mask & value) != 0):\n",
        "      print(array[i],\" \")\n",
        "      sum = sum + array[i]\n",
        "    mask = mask * 2\n",
        "  print(\" sum: \",sum)\n",
        "  print(\"Second partition: \")\n",
        "  mask = 1\n",
        "  sum = 0\n",
        "  for i in range(0,n):\n",
        "    if ((mask & value) == 0):\n",
        "      print(array[i],\" \")\n",
        "      sum = sum + array[i]\n",
        "    mask = mask * 2\n",
        "  print(\" sum: \\n\",sum)\n",
        "\n",
        "def parallelFor(n,array,nPartitions):\n",
        "  solutionFound = 0\n",
        "  solution = -1\n",
        "  result = np.zeros(nPartitions,dtype=np.int64)\n",
        "  arrayGPU = cuda.to_device(array)\n",
        "  resultGPU = cuda.to_device(result)\n",
        "  evaluatePartition.forall(nPartitions)( arrayGPU,resultGPU, n)\n",
        "  # Copy the result array back to the CPU\n",
        "  resultGPU.copy_to_host(result)\n",
        "  solutionFound = np.max(result)\n",
        "  solution = solutionFound\n",
        "  if (solutionFound):\n",
        "    printResults(solution, n, array)\n",
        "  else:\n",
        "    print(\"No solution was found.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  start = time.time()\n",
        "  # Read the problem\n",
        "  n = int(input())\n",
        "  valuesString = input()\n",
        "  values = valuesString.split()\n",
        "  for i in range(len(values)):\n",
        "    values[i] = int(values[i])\n",
        "# Print the instance of the problem\n",
        "  print(\"Problem size: \",n)\n",
        "  print(\"Problem instance: \",values)\n",
        "  nPartitions = 2 ** n\n",
        "  np_array = np.array(values)\n",
        "  parallelFor(n,np_array,nPartitions)\n",
        "  end = time.time()\n",
        "  elapsed = end - start\n",
        "  print(\"The program took: \",elapsed,\" seconds.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D8xF3hwesoPT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's execute the code with several test cases."
      ],
      "metadata": {
        "id": "wj2ywue6sJua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile instanceNoSolution24.Text\n",
        "24\n",
        "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 1000000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cX2kQ_uvfrgh",
        "outputId": "2f482c69-8e1e-45c3-dece-7b892b660d5a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing instanceNoSolution24.Text\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python partition_numba_cuda.py < instanceNoSolution24.Text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuDIsNWEgQAy",
        "outputId": "195e8289-e844-4f5c-f316-e37cabb2d7c6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem size:  24\n",
            "Problem instance:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 1000000]\n",
            "No solution was found.\n",
            "The program took:  1.1637372970581055  seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test27.Text\n",
        "27\n",
        "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_qEwwgHpInD",
        "outputId": "57edf3d0-0dee-46bb-e196-2c9faf8aadc8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing test27.Text\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python partition_numba_cuda.py < test27.Text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yZnV3oCpNdr",
        "outputId": "a60d5538-6cf1-44c2-c165-1ab06fad7d5e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem size:  27\n",
            "Problem instance:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n",
            "Solution:\n",
            "\n",
            "First partition: \n",
            "1  \n",
            "20  \n",
            "21  \n",
            "22  \n",
            "23  \n",
            "24  \n",
            "25  \n",
            "26  \n",
            "27  \n",
            " sum:  189\n",
            "Second partition: \n",
            "2  \n",
            "3  \n",
            "4  \n",
            "5  \n",
            "6  \n",
            "7  \n",
            "8  \n",
            "9  \n",
            "10  \n",
            "11  \n",
            "12  \n",
            "13  \n",
            "14  \n",
            "15  \n",
            "16  \n",
            "17  \n",
            "18  \n",
            "19  \n",
            " sum: \n",
            " 189\n",
            "The program took:  2.226382255554199  seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test28.Text\n",
        "28\n",
        "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPWgzBoFnvgq",
        "outputId": "e7ccd7ba-c2ea-4da7-b631-590cbd596df0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing test28.Text\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python partition_numba_cuda.py < test28.Text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrlP7fzvn05p",
        "outputId": "b05b3567-7697-462b-acd7-79e54ae105c3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem size:  28\n",
            "Problem instance:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28]\n",
            "Solution:\n",
            "\n",
            "First partition: \n",
            "7  \n",
            "21  \n",
            "22  \n",
            "23  \n",
            "24  \n",
            "25  \n",
            "26  \n",
            "27  \n",
            "28  \n",
            " sum:  203\n",
            "Second partition: \n",
            "1  \n",
            "2  \n",
            "3  \n",
            "4  \n",
            "5  \n",
            "6  \n",
            "8  \n",
            "9  \n",
            "10  \n",
            "11  \n",
            "12  \n",
            "13  \n",
            "14  \n",
            "15  \n",
            "16  \n",
            "17  \n",
            "18  \n",
            "19  \n",
            "20  \n",
            " sum: \n",
            " 203\n",
            "The program took:  3.753606081008911  seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test29.Text\n",
        "29\n",
        "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JR2eHwuhpW4x",
        "outputId": "b5915fab-daa8-4423-bbec-6282396fa298"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing test29.Text\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python partition_numba_cuda.py < test29.Text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPgYOCxDpcnr",
        "outputId": "6cb3b5c5-ea13-42a0-d993-a784b3efee6f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem size:  29\n",
            "Problem instance:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
            "No solution was found.\n",
            "The program took:  7.365434885025024  seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test30.Text\n",
        "30\n",
        "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQmTh7nxprCj",
        "outputId": "25cdd88b-1286-4498-ddba-750ff9cf74ec"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing test30.Text\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python partition_numba_cuda.py < test30.Text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADkc1Lorpu5L",
        "outputId": "05a7c23a-6287-413a-a286-0ceb63d92c85"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem size:  30\n",
            "Problem instance:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
            "No solution was found.\n",
            "The program took:  14.038873434066772  seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lscpu"
      ],
      "metadata": {
        "id": "qT1xPX7pAUxM",
        "outputId": "27202457-1bab-445c-88c5-e834b42956aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Architecture:            x86_64\n",
            "  CPU op-mode(s):        32-bit, 64-bit\n",
            "  Address sizes:         46 bits physical, 48 bits virtual\n",
            "  Byte Order:            Little Endian\n",
            "CPU(s):                  2\n",
            "  On-line CPU(s) list:   0,1\n",
            "Vendor ID:               GenuineIntel\n",
            "  Model name:            Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "    CPU family:          6\n",
            "    Model:               85\n",
            "    Thread(s) per core:  2\n",
            "    Core(s) per socket:  1\n",
            "    Socket(s):           1\n",
            "    Stepping:            3\n",
            "    BogoMIPS:            4000.29\n",
            "    Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clf\n",
            "                         lush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_\n",
            "                         good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fm\n",
            "                         a cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hyp\n",
            "                         ervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsb\n",
            "                         ase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512d\n",
            "                         q rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsave\n",
            "                         c xgetbv1 xsaves arat md_clear arch_capabilities\n",
            "Virtualization features: \n",
            "  Hypervisor vendor:     KVM\n",
            "  Virtualization type:   full\n",
            "Caches (sum of all):     \n",
            "  L1d:                   32 KiB (1 instance)\n",
            "  L1i:                   32 KiB (1 instance)\n",
            "  L2:                    1 MiB (1 instance)\n",
            "  L3:                    38.5 MiB (1 instance)\n",
            "NUMA:                    \n",
            "  NUMA node(s):          1\n",
            "  NUMA node0 CPU(s):     0,1\n",
            "Vulnerabilities:         \n",
            "  Gather data sampling:  Not affected\n",
            "  Itlb multihit:         Not affected\n",
            "  L1tf:                  Mitigation; PTE Inversion\n",
            "  Mds:                   Vulnerable; SMT Host state unknown\n",
            "  Meltdown:              Vulnerable\n",
            "  Mmio stale data:       Vulnerable\n",
            "  Retbleed:              Vulnerable\n",
            "  Spec rstack overflow:  Not affected\n",
            "  Spec store bypass:     Vulnerable\n",
            "  Spectre v1:            Vulnerable: __user pointer sanitization and usercopy barriers only; no swap\n",
            "                         gs barriers\n",
            "  Spectre v2:            Vulnerable, IBPB: disabled, STIBP: disabled, PBRSB-eIBRS: Not affected\n",
            "  Srbds:                 Not affected\n",
            "  Tsx async abort:       Vulnerable\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "Fp1Ae8JYAmq1",
        "outputId": "9049ee8a-e053-49ca-ec10-1e937ee31292",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jan 31 16:17:52 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   60C    P0              35W /  70W |      0MiB / 15360MiB |     50%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile instanceNoSolution25.Text\n",
        "25\n",
        "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 1000000"
      ],
      "metadata": {
        "id": "fu0K4otgTqen",
        "outputId": "0c71f0b7-6e12-4454-9fca-eb917a1827ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting instanceNoSolution25.Text\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python partition_numba_cuda.py < instanceNoSolution25.Text"
      ],
      "metadata": {
        "id": "F0CrLqdOTv5P",
        "outputId": "0b716054-251d-4d8b-c8fb-33e064027330",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem size:  25\n",
            "Problem instance:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 1000000]\n",
            "No solution was found.\n",
            "The program took:  0.781346321105957  seconds.\n"
          ]
        }
      ]
    }
  ]
}