{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMk8Jz6mP7xQiyHKLwhwi/C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trefftzc/partition_COLAB_notebooks/blob/main/partition_thrust.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Thrust\n",
        "\n",
        "Thrust is a C++ library that NVIDIA has created to simplify the programming of GPUs.\n",
        "\n",
        "The web site for Thrust is:\n",
        " https://developer.nvidia.com/thrust\n",
        "\n",
        " Thrust uses similar design principles to the STL library in C++.\n",
        "\n",
        " One of the most used classes in STL is the class vector.\n",
        "\n",
        " Thrust extends the class vector with two specialized classes:\n",
        "\n",
        " host_vector\n",
        "\n",
        " and\n",
        "  \n",
        " device_vector\n",
        "\n",
        " host_vector instances are allocated in the memory of the host while device_vector instances are allocated in the memory of the GPU.\n",
        "\n",
        " Copying back and forth can be done with a simple assignment.\n",
        "\n",
        "\n",
        " The kernels that one uses in CUDA are replaced with functors where one adds the keywords __host__ and/or __device__ to indicate where those functors can be executed.\n",
        " functors are C++ functions that can be applied to all the entries in a vector.\n",
        "\n",
        " One uses the transform primitive in C++ to apply a functor to all the elements of a vector and then to store the results in another vector.\n",
        "\n",
        " Thurst also offers a number of powerful primitives, for instance reduction operations."
      ],
      "metadata": {
        "id": "vGt0Xn4VeAvZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_XuBwENL2MV",
        "outputId": "ac83f013-8df6-4df0-982f-7990d7378342"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing partition_thrust.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile partition_thrust.cu\n",
        "//\n",
        "// The Thrust documentation is available at\n",
        "// https://docs.nvidia.com/cuda/thrust/index.html\n",
        "//\n",
        "#include <thrust/host_vector.h>\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/sequence.h>\n",
        "#include <thrust/reduce.h>\n",
        "#include <thrust/functional.h>\n",
        "#include <thrust/execution_policy.h>\n",
        "\n",
        "#include <iostream>\n",
        "\n",
        "\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "// In Thrust, kernels are written as functors in C++\n",
        "// With the additional use of the keywords\n",
        "// __host__\n",
        "// __device__\n",
        "// The keyword __host__ states that this functor can be used on the host\n",
        "// The keyword __device__ states that this functor can be used on the device\n",
        "\n",
        "\n",
        "// This functor evaluates a subset encoded by an integer value\n",
        "// as a possible solution to the partition problem.\n",
        "// If this subset is indeed a solution, then the result is the\n",
        "// value of the integer that encodes the subset.\n",
        "// Otherwise the result is 0.\n",
        "\n",
        "// Thus the vector with the results will contain non-zero values\n",
        "// in the entries that encode subsets that are solutions to this\n",
        "// particular instance of the problem.\n",
        "// If the instance of the problem does not have any solutions,\n",
        "// the entire vector with results will contain 0s.\n",
        "\n",
        "struct evaluateFunctor\n",
        "{\n",
        "\n",
        "  const int n;\n",
        "  const int *array;\n",
        "\n",
        "  evaluateFunctor(int _n,int *_array) : n(_n),array(_array) {}\n",
        "    __host__ __device__\n",
        "\n",
        "    int operator()( const int value) {\n",
        "      int sum0s = 0;\n",
        "      int sum1s = 0;\n",
        "      unsigned int mask = 1;\n",
        "      for(int i = 0;i < n;i++) {\n",
        "        if ((mask & value) != 0) {\n",
        "          sum1s = sum1s + array[i];\n",
        "        }\n",
        "        else {\n",
        "          sum0s = sum0s + array[i];\n",
        "        }\n",
        "        mask = mask * 2;\n",
        "      }\n",
        "      if (sum0s == sum1s)\n",
        "        return value;\n",
        "      else\n",
        "        return 0;\n",
        "  }\n",
        "\n",
        "};\n",
        "\n",
        "void printResults(int value,int n,thrust::host_vector < int > array)\n",
        "{\n",
        "  cout << \"Solution:\\n\" << endl;\n",
        "  cout << \"First partition: \" << endl ;\n",
        "  unsigned int mask = 1;\n",
        "  int sum = 0;\n",
        "  for(int i = 0;i < n;i++) {\n",
        "    if ((mask & value) != 0) {\n",
        "      cout << array[i] << \" \";\n",
        "      sum = sum + array[i];\n",
        "    }\n",
        "    mask = mask * 2;\n",
        "  }\n",
        "  cout << \" sum: \" << sum << endl;\n",
        "  cout << \"Second partition: \" << endl ;\n",
        "  mask = 1;\n",
        "  sum = 0;\n",
        "  for(int i = 0;i < n;i++) {\n",
        "    if ((mask & value) == 0) {\n",
        "      cout << array[i] << \" \";\n",
        "      sum = sum + array[i];\n",
        "    }\n",
        "    mask = mask * 2;\n",
        "  }\n",
        "  cout << \" sum: \" << sum << endl;\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "    // Read the instance of the problem from standard input\n",
        "    // Read first the size of the problem\n",
        "\n",
        "    int n;\n",
        "    cin >> n;\n",
        "\n",
        "    // Allocate an array in the host and read the n integer values\n",
        "\n",
        "    thrust::host_vector < int > host_array(n);\n",
        "    for(int i = 0;i < n;i++) {\n",
        "      cin >> host_array[i];\n",
        "    }\n",
        "\n",
        "    // Now allocate a device_vector and copy\n",
        "    // the host_vector to the GPU memory\n",
        "\n",
        "    thrust::device_vector < int > device_array(n);\n",
        "    device_array = host_array;\n",
        "\n",
        "    // Generate the sequence of integer values\n",
        "    // that encode all the possible subsets\n",
        "\n",
        "    int powerOf2 = 1;\n",
        "    for(int i = 0;i < n-1;i++) {\n",
        "      powerOf2 = powerOf2 * 2;\n",
        "    }\n",
        "    std::cout << \"Number of subsets to evaluate is : \" << powerOf2 << std::endl;\n",
        "    thrust::host_vector<int> sequentialValues(powerOf2);\n",
        "    // cout << \"Allocated sequentialValues.\" << endl;\n",
        "    thrust::sequence(sequentialValues.begin(),sequentialValues.end());\n",
        "    thrust::device_vector<int>  is_solution(powerOf2);\n",
        "    // cout << \"Allocated is_solution.\" << endl;\n",
        "    thrust::device_vector<int> encodingOfSubset(powerOf2);\n",
        "    // cout << \"Allocated encodigOfSubset.\" << endl;\n",
        "    encodingOfSubset = sequentialValues;\n",
        "    // cout << \"Copied data to GPU.\" << endl;\n",
        "\n",
        "\n",
        "    // Instantiate the functor\n",
        "\n",
        "    evaluateFunctor ef(n,thrust::raw_pointer_cast(device_array.data()));\n",
        "    // cout << \"Instantiated functor \" << endl;\n",
        "    // Execute the kernel. In this case a C++ functor\n",
        "    // transform applies a functor to the input parameters\n",
        "    // and leaves the result in the last parameter\n",
        "    thrust::transform(encodingOfSubset.begin(), encodingOfSubset.end(),\n",
        "                        is_solution.begin(), ef);\n",
        "    // cout << \"Performed transformation.\" << endl;\n",
        "    int result = thrust::reduce(\n",
        "                            is_solution.begin(),is_solution.end(),\n",
        "                            0,\n",
        "                            thrust::maximum<int>());\n",
        "    // cout << \"result is: \" << result << endl;\n",
        "    if (result == 0)\n",
        "       cout << \"This instance does not have a solution. \" << endl;\n",
        "    else\n",
        "\t    printResults(result,n,host_array);\n",
        "\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc partition_thrust.cu -o partition_thrust -O3\n"
      ],
      "metadata": {
        "id": "473XJ_tVPKN5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_with_solution_24.txt\n",
        "24\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 23"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67FCVowgPpPD",
        "outputId": "1231ff4a-1b22-49c1-c187-d9c2614f6dc5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing test_with_solution_24.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!time ./partition_thrust < test_with_solution_24.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LW36fj38YzRs",
        "outputId": "e9a3ddd1-7abe-4115-83b2-4a7c2e8de61c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of subsets to evaluate is : 8388608\n",
            "Solution:\n",
            "\n",
            "First partition: \n",
            "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1  sum: 23\n",
            "Second partition: \n",
            "23  sum: 23\n",
            "\n",
            "real\t0m0.169s\n",
            "user\t0m0.033s\n",
            "sys\t0m0.132s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_with_no_solution_24.txt\n",
        "24\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "secaTyXpgS8M",
        "outputId": "6846d90a-3983-4064-b013-24c21c475745"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting test_with_no_solution_24.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_with_no_solution_29.txt\n",
        "29\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 32"
      ],
      "metadata": {
        "id": "3NLd3QWxof2Z",
        "outputId": "fc4e1292-c609-47d1-e9f5-36f0c402d663",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing test_with_no_solution_29.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!time ./partition_thrust < test_with_no_solution_29.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGK6nmLwgYY9",
        "outputId": "17ebbc84-e42e-4e7c-8dab-f7eb92539254"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of subsets to evaluate is : 268435456\n",
            "This instance does not have a solution. \n",
            "\n",
            "real\t0m1.159s\n",
            "user\t0m0.502s\n",
            "sys\t0m0.642s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./partition_thrust < test_with_no_solution_24.txt\n"
      ],
      "metadata": {
        "id": "S39n90Conmox",
        "outputId": "21d49dc3-e710-4148-f0ff-dd8d5436980f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==3016== NVPROF is profiling process 3016, command: ./partition_thrust\n",
            "Number of subsets to evaluate is : 8388608\n",
            "This instance does not have a solution. \n",
            "==3016== Profiling application: ./partition_thrust\n",
            "==3016== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   84.24%  6.6644ms         2  3.3322ms     672ns  6.6637ms  [CUDA memcpy HtoD]\n",
            "                   10.16%  803.79us         1  803.79us  803.79us  803.79us  void thrust::cuda_cub::core::_kernel_agent<thrust::cuda_cub::__parallel_for::ParallelForAgent<thrust::cuda_cub::__transform::unary_transform_f<thrust::detail::normal_iterator<thrust::device_ptr<int>>, thrust::detail::normal_iterator<thrust::device_ptr<int>>, thrust::cuda_cub::__transform::no_stencil_tag, evaluateFunctor, thrust::cuda_cub::__transform::always_true_predicate>, long>, thrust::cuda_cub::__transform::unary_transform_f<thrust::detail::normal_iterator<thrust::device_ptr<int>>, thrust::detail::normal_iterator<thrust::device_ptr<int>>, thrust::cuda_cub::__transform::no_stencil_tag, evaluateFunctor, thrust::cuda_cub::__transform::always_true_predicate>, long>(thrust::device_ptr<int>, thrust::detail::normal_iterator<thrust::device_ptr<int>>)\n",
            "                    3.72%  294.42us         3  98.141us  3.0400us  147.13us  void thrust::cuda_cub::core::_kernel_agent<thrust::cuda_cub::__parallel_for::ParallelForAgent<thrust::cuda_cub::__uninitialized_fill::functor<thrust::device_ptr<int>, int>, unsigned long>, thrust::cuda_cub::__uninitialized_fill::functor<thrust::device_ptr<int>, int>, unsigned long>(thrust::device_ptr<int>, int)\n",
            "                    1.77%  140.32us         1  140.32us  140.32us  140.32us  void cub::CUB_200200_520_NS::DeviceReduceKernel<cub::CUB_200200_520_NS::DeviceReducePolicy<int, unsigned int, thrust::maximum<int>>::Policy600, thrust::detail::normal_iterator<thrust::device_ptr<int>>, unsigned int, thrust::maximum<int>, int>(unsigned int, cub::CUB_200200_520_NS::DeviceReducePolicy<int, unsigned int, thrust::maximum<int>>::Policy600*, int, cub::CUB_200200_520_NS::GridEvenShare<cub::CUB_200200_520_NS::DeviceReducePolicy<int, unsigned int, thrust::maximum<int>>::Policy600*>, thrust::maximum<int>)\n",
            "                    0.07%  5.7920us         1  5.7920us  5.7920us  5.7920us  void cub::CUB_200200_520_NS::DeviceReduceSingleTileKernel<cub::CUB_200200_520_NS::DeviceReducePolicy<int, unsigned int, thrust::maximum<int>>::Policy600, int*, int*, int, thrust::maximum<int>, int, int>(unsigned int, int, thrust::maximum<int>, cub::CUB_200200_520_NS::DeviceReducePolicy<int, unsigned int, thrust::maximum<int>>::Policy600, int*)\n",
            "                    0.03%  2.0160us         1  2.0160us  2.0160us  2.0160us  [CUDA memcpy DtoH]\n",
            "      API calls:   89.61%  106.01ms         4  26.502ms  15.234us  105.66ms  cudaMalloc\n",
            "                    5.81%  6.8746ms         3  2.2915ms  22.758us  6.8277ms  cudaMemcpyAsync\n",
            "                    1.25%  1.4777ms         4  369.43us  17.243us  1.0958ms  cudaFree\n",
            "                    1.16%  1.3740ms         1  1.3740ms  1.3740ms  1.3740ms  cudaFuncGetAttributes\n",
            "                    1.13%  1.3312ms         8  166.40us  1.7070us  805.87us  cudaStreamSynchronize\n",
            "                    0.71%  841.42us         2  420.71us  1.0260us  840.40us  cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags\n",
            "                    0.18%  214.29us       114  1.8790us     208ns  71.744us  cuDeviceGetAttribute\n",
            "                    0.10%  117.24us         6  19.539us  8.3350us  33.735us  cudaLaunchKernel\n",
            "                    0.01%  13.842us         1  13.842us  13.842us  13.842us  cuDeviceGetName\n",
            "                    0.01%  11.748us        69     170ns     118ns     874ns  cudaGetLastError\n",
            "                    0.01%  9.4050us        13     723ns     280ns  1.9130us  cudaGetDevice\n",
            "                    0.01%  6.4140us         6  1.0690us     558ns  1.7310us  cudaDeviceGetAttribute\n",
            "                    0.01%  6.2430us         1  6.2430us  6.2430us  6.2430us  cuDeviceTotalMem\n",
            "                    0.00%  4.8790us         1  4.8790us  4.8790us  4.8790us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.3490us         3     783ns     350ns  1.5910us  cuDeviceGetCount\n",
            "                    0.00%  1.9770us        12     164ns     122ns     227ns  cudaPeekAtLastError\n",
            "                    0.00%  1.2570us         2     628ns     313ns     944ns  cuDeviceGet\n",
            "                    0.00%     615ns         1     615ns     615ns     615ns  cuDeviceGetUuid\n",
            "                    0.00%     600ns         1     600ns     600ns     600ns  cuModuleGetLoadingMode\n",
            "                    0.00%     233ns         1     233ns     233ns     233ns  cudaGetDeviceCount\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./partition_thrust < test_with_no_solution_29.txt"
      ],
      "metadata": {
        "id": "c7_R2PFOoyya",
        "outputId": "0a72d425-6d54-41fb-bbd6-162934157468",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==4350== NVPROF is profiling process 4350, command: ./partition_thrust\n",
            "Number of subsets to evaluate is : 268435456\n",
            "This instance does not have a solution. \n",
            "==4350== Profiling application: ./partition_thrust\n",
            "==4350== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   84.13%  232.10ms         2  116.05ms     640ns  232.10ms  [CUDA memcpy HtoD]\n",
            "                   10.83%  29.867ms         1  29.867ms  29.867ms  29.867ms  void thrust::cuda_cub::core::_kernel_agent<thrust::cuda_cub::__parallel_for::ParallelForAgent<thrust::cuda_cub::__transform::unary_transform_f<thrust::detail::normal_iterator<thrust::device_ptr<int>>, thrust::detail::normal_iterator<thrust::device_ptr<int>>, thrust::cuda_cub::__transform::no_stencil_tag, evaluateFunctor, thrust::cuda_cub::__transform::always_true_predicate>, long>, thrust::cuda_cub::__transform::unary_transform_f<thrust::detail::normal_iterator<thrust::device_ptr<int>>, thrust::detail::normal_iterator<thrust::device_ptr<int>>, thrust::cuda_cub::__transform::no_stencil_tag, evaluateFunctor, thrust::cuda_cub::__transform::always_true_predicate>, long>(thrust::device_ptr<int>, thrust::detail::normal_iterator<thrust::device_ptr<int>>)\n",
            "                    3.35%  9.2519ms         3  3.0840ms  3.0070us  4.6257ms  void thrust::cuda_cub::core::_kernel_agent<thrust::cuda_cub::__parallel_for::ParallelForAgent<thrust::cuda_cub::__uninitialized_fill::functor<thrust::device_ptr<int>, int>, unsigned long>, thrust::cuda_cub::__uninitialized_fill::functor<thrust::device_ptr<int>, int>, unsigned long>(thrust::device_ptr<int>, int)\n",
            "                    1.68%  4.6408ms         1  4.6408ms  4.6408ms  4.6408ms  void cub::CUB_200200_520_NS::DeviceReduceKernel<cub::CUB_200200_520_NS::DeviceReducePolicy<int, unsigned int, thrust::maximum<int>>::Policy600, thrust::detail::normal_iterator<thrust::device_ptr<int>>, unsigned int, thrust::maximum<int>, int>(unsigned int, cub::CUB_200200_520_NS::DeviceReducePolicy<int, unsigned int, thrust::maximum<int>>::Policy600*, int, cub::CUB_200200_520_NS::GridEvenShare<cub::CUB_200200_520_NS::DeviceReducePolicy<int, unsigned int, thrust::maximum<int>>::Policy600*>, thrust::maximum<int>)\n",
            "                    0.00%  5.6960us         1  5.6960us  5.6960us  5.6960us  void cub::CUB_200200_520_NS::DeviceReduceSingleTileKernel<cub::CUB_200200_520_NS::DeviceReducePolicy<int, unsigned int, thrust::maximum<int>>::Policy600, int*, int*, int, thrust::maximum<int>, int, int>(unsigned int, int, thrust::maximum<int>, cub::CUB_200200_520_NS::DeviceReducePolicy<int, unsigned int, thrust::maximum<int>>::Policy600, int*)\n",
            "                    0.00%  3.0400us         1  3.0400us  3.0400us  3.0400us  [CUDA memcpy DtoH]\n",
            "      API calls:   61.50%  232.32ms         3  77.440ms  14.251us  232.28ms  cudaMemcpyAsync\n",
            "                   25.02%  94.503ms         4  23.626ms  23.873us  92.175ms  cudaMalloc\n",
            "                   11.61%  43.872ms         8  5.4840ms  1.8690us  29.871ms  cudaStreamSynchronize\n",
            "                    1.40%  5.3051ms         4  1.3263ms  7.8310us  2.8894ms  cudaFree\n",
            "                    0.36%  1.3478ms         1  1.3478ms  1.3478ms  1.3478ms  cudaFuncGetAttributes\n",
            "                    0.04%  169.67us         6  28.278us  9.1090us  40.710us  cudaLaunchKernel\n",
            "                    0.03%  131.45us       114  1.1530us     140ns  51.643us  cuDeviceGetAttribute\n",
            "                    0.01%  32.305us         2  16.152us     655ns  31.650us  cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags\n",
            "                    0.01%  20.331us        69     294ns     128ns  5.6540us  cudaGetLastError\n",
            "                    0.00%  15.895us         1  15.895us  15.895us  15.895us  cuDeviceGetName\n",
            "                    0.00%  14.321us        13  1.1010us     292ns  3.0300us  cudaGetDevice\n",
            "                    0.00%  9.5060us         6  1.5840us     441ns  2.0720us  cudaDeviceGetAttribute\n",
            "                    0.00%  5.4490us         1  5.4490us  5.4490us  5.4490us  cuDeviceGetPCIBusId\n",
            "                    0.00%  4.7420us         1  4.7420us  4.7420us  4.7420us  cuDeviceTotalMem\n",
            "                    0.00%  2.1940us        12     182ns     132ns     244ns  cudaPeekAtLastError\n",
            "                    0.00%  1.3130us         3     437ns     180ns     889ns  cuDeviceGetCount\n",
            "                    0.00%  1.2050us         2     602ns     188ns  1.0170us  cuDeviceGet\n",
            "                    0.00%     492ns         1     492ns     492ns     492ns  cuModuleGetLoadingMode\n",
            "                    0.00%     343ns         1     343ns     343ns     343ns  cuDeviceGetUuid\n",
            "                    0.00%     339ns         1     339ns     339ns     339ns  cudaGetDeviceCount\n"
          ]
        }
      ]
    }
  ]
}