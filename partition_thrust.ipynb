{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyORLO+YDhcwirdqyuUT5vfc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trefftzc/partition_COLAB_notebooks/blob/main/partition_thrust.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Thrust\n",
        "\n",
        "Thrust is a C++ library that NVIDIA has created to simplify the programming of GPUs.\n",
        "\n",
        "The web site for Thrust is:\n",
        " https://developer.nvidia.com/thrust\n",
        "\n",
        " Thrust uses similar design principles to the STL library in C++.\n",
        "\n",
        " One of the most used classes in STL is the class vector.\n",
        "\n",
        " Thrust extends the class vector with two specialized classes:\n",
        "\n",
        " host_vector\n",
        "\n",
        " and\n",
        "  \n",
        " device_vector\n",
        "\n",
        " host_vector instances are allocated in the memory of the host while device_vector instances are allocated in the memory of the GPU.\n",
        "\n",
        " Copying back and forth can be done with a simple assignment.\n",
        "\n",
        "\n",
        " The kernels that one uses in CUDA are replaced with functors where one adds the keywords __host__ and/or __device__ to indicate where those functors can be executed.\n",
        " functors are C++ functions that can be applied to all the entries in a vector.\n",
        "\n",
        " One uses the transform primitive in C++ to apply a functor to all the elements of a vector and then to store the results in another vector.\n",
        "\n",
        " Thurst also offers a number of powerful primitives, for instance reduction operations."
      ],
      "metadata": {
        "id": "vGt0Xn4VeAvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NVIDIA/cccl.git\n"
      ],
      "metadata": {
        "id": "u-KXex2kjcPR",
        "outputId": "3b47f516-65cf-45f1-fccb-a57093974167",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'cccl' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_XuBwENL2MV",
        "outputId": "19cf3b3b-a007-4a6c-e519-f0a3bbb929a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting partition_thrust.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile partition_thrust.cu\n",
        "//\n",
        "// The Thrust documentation is available at\n",
        "// https://docs.nvidia.com/cuda/thrust/index.html\n",
        "//\n",
        "#include <thrust/host_vector.h>\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/sequence.h>\n",
        "#include <thrust/reduce.h>\n",
        "#include <thrust/functional.h>\n",
        "#include <thrust/execution_policy.h>\n",
        "\n",
        "#include <iostream>\n",
        "\n",
        "\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "// In Thrust, kernels are written as functors in C++\n",
        "// With the additional use of the keywords\n",
        "// __host__\n",
        "// __device__\n",
        "// The keyword __host__ states that this functor can be used on the host\n",
        "// The keyword __device__ states that this functor can be used on the device\n",
        "\n",
        "\n",
        "// This functor evaluates a subset encoded by an integer value\n",
        "// as a possible solution to the partition problem.\n",
        "// If this subset is indeed a solution, then the result is the\n",
        "// value of the integer that encodes the subset.\n",
        "// Otherwise the result is 0.\n",
        "\n",
        "// Thus the vector with the results will contain non-zero values\n",
        "// in the entries that encode subsets that are solutions to this\n",
        "// particular instance of the problem.\n",
        "// If the instance of the problem does not have any solutions,\n",
        "// the entire vector with results will contain 0s.\n",
        "\n",
        "struct evaluateFunctor\n",
        "{\n",
        "\n",
        "  const int n;\n",
        "  const int *array;\n",
        "\n",
        "  evaluateFunctor(int _n,int *_array) : n(_n),array(_array) {}\n",
        "    __host__ __device__\n",
        "\n",
        "    int operator()( const int value) {\n",
        "      int sum0s = 0;\n",
        "      int sum1s = 0;\n",
        "      unsigned int mask = 1;\n",
        "      for(int i = 0;i < n;i++) {\n",
        "        if ((mask & value) != 0) {\n",
        "          sum1s = sum1s + array[i];\n",
        "        }\n",
        "        else {\n",
        "          sum0s = sum0s + array[i];\n",
        "        }\n",
        "        mask = mask * 2;\n",
        "      }\n",
        "      if (sum0s == sum1s)\n",
        "        return value;\n",
        "      else\n",
        "        return 0;\n",
        "  }\n",
        "\n",
        "};\n",
        "\n",
        "void printResults(int value,int n,thrust::host_vector < int > array)\n",
        "{\n",
        "  cout << \"Solution:\\n\" << endl;\n",
        "  cout << \"First partition: \" << endl ;\n",
        "  unsigned int mask = 1;\n",
        "  int sum = 0;\n",
        "  for(int i = 0;i < n;i++) {\n",
        "    if ((mask & value) != 0) {\n",
        "      cout << array[i] << \" \";\n",
        "      sum = sum + array[i];\n",
        "    }\n",
        "    mask = mask * 2;\n",
        "  }\n",
        "  cout << \" sum: \" << sum << endl;\n",
        "  cout << \"Second partition: \" << endl ;\n",
        "  mask = 1;\n",
        "  sum = 0;\n",
        "  for(int i = 0;i < n;i++) {\n",
        "    if ((mask & value) == 0) {\n",
        "      cout << array[i] << \" \";\n",
        "      sum = sum + array[i];\n",
        "    }\n",
        "    mask = mask * 2;\n",
        "  }\n",
        "  cout << \" sum: \" << sum << endl;\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "    // Read the instance of the problem from standard input\n",
        "    // Read first the size of the problem\n",
        "\n",
        "    int n;\n",
        "    cin >> n;\n",
        "\n",
        "    // Allocate an array in the host and read the n integer values\n",
        "\n",
        "    thrust::host_vector < int > host_array(n);\n",
        "    for(int i = 0;i < n;i++) {\n",
        "      cin >> host_array[i];\n",
        "    }\n",
        "\n",
        "    // Now allocate a device_vector and copy\n",
        "    // the host_vector to the GPU memory\n",
        "\n",
        "    thrust::device_vector < int > device_array(n);\n",
        "    device_array = host_array;\n",
        "\n",
        "    // Generate the sequence of integer values\n",
        "    // that encode all the possible subsets\n",
        "\n",
        "    int powerOf2 = 1;\n",
        "    for(int i = 0;i < n-1;i++) {\n",
        "      powerOf2 = powerOf2 * 2;\n",
        "    }\n",
        "    std::cout << \"Number of subsets to evaluate is : \" << powerOf2 << std::endl;\n",
        "    // is_solution will contain the results of the evaluation\n",
        "    // It is allocated in the GPU memory\n",
        "    thrust::device_vector<int>  is_solution(powerOf2);\n",
        "\n",
        "    // encodingOfSubset will contain the sequence of integer values\n",
        "    // that encode all the possible subsets\n",
        "    // It is allocated in the GPU memory\n",
        "    thrust::device_vector<int> encodingOfSubset(powerOf2);\n",
        "\n",
        "    //  The sequence function in Thrust initializes the array\n",
        "    // encodingOfSubset with the sequence of integer values\n",
        "    // from 0 to powerOf2-1\n",
        "    thrust::sequence(encodingOfSubset.begin(),encodingOfSubset.end());\n",
        "\n",
        "\n",
        "\n",
        "    // Instantiate the functor\n",
        "\n",
        "    evaluateFunctor ef(n,thrust::raw_pointer_cast(device_array.data()));\n",
        "    // cout << \"Instantiated functor \" << endl;\n",
        "    // Execute the kernel. In this case a C++ functor\n",
        "    // transform applies a functor to the input parameters\n",
        "    // and leaves the result in the last parameter\n",
        "    thrust::transform(encodingOfSubset.begin(), encodingOfSubset.end(),\n",
        "                        is_solution.begin(), ef);\n",
        "    // cout << \"Performed transformation.\" << endl;\n",
        "    int result = thrust::reduce(\n",
        "                            is_solution.begin(),is_solution.end(),\n",
        "                            0,\n",
        "                            thrust::maximum<int>());\n",
        "    // cout << \"result is: \" << result << endl;\n",
        "    if (result == 0)\n",
        "       cout << \"This instance does not have a solution. \" << endl;\n",
        "    else\n",
        "\t    printResults(result,n,host_array);\n",
        "\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -Icccl/thrust -Icccl/libcudacxx/include -Icccl/cub partition_thrust.cu -o partition_thrust -arch sm_75\n"
      ],
      "metadata": {
        "id": "473XJ_tVPKN5"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_with_solution_24.txt\n",
        "24\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 23"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67FCVowgPpPD",
        "outputId": "db5f6d23-6dc5-4644-cb4b-eec8d484f0e4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting test_with_solution_24.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!time ./partition_thrust < test_with_solution_24.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LW36fj38YzRs",
        "outputId": "519fa896-5180-4392-ca54-c48fb68fb0ba"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of subsets to evaluate is : 8388608\n",
            "Solution:\n",
            "\n",
            "First partition: \n",
            "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1  sum: 23\n",
            "Second partition: \n",
            "23  sum: 23\n",
            "\n",
            "real\t0m0.230s\n",
            "user\t0m0.017s\n",
            "sys\t0m0.210s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_with_no_solution_24.txt\n",
        "24\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "secaTyXpgS8M",
        "outputId": "37feb3b2-8b65-4edb-9061-4b7045066835"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting test_with_no_solution_24.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_with_no_solution_29.txt\n",
        "29\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 32"
      ],
      "metadata": {
        "id": "3NLd3QWxof2Z",
        "outputId": "8b1a575e-a75b-4168-ed7a-c0ed25b9e342",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting test_with_no_solution_29.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!time ./partition_thrust < test_with_no_solution_29.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGK6nmLwgYY9",
        "outputId": "c902f94f-e247-4771-e2d2-f2d8311e1e59"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of subsets to evaluate is : 268435456\n",
            "This instance does not have a solution. \n",
            "\n",
            "real\t0m0.318s\n",
            "user\t0m0.060s\n",
            "sys\t0m0.255s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./partition_thrust < test_with_no_solution_24.txt\n"
      ],
      "metadata": {
        "id": "S39n90Conmox",
        "outputId": "eaedc07d-f029-47b9-8b92-22a7fb3d07c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==4490== NVPROF is profiling process 4490, command: ./partition_thrust\n",
            "Number of subsets to evaluate is : 8388608\n",
            "This instance does not have a solution. \n",
            "==4490== Profiling application: ./partition_thrust\n",
            "==4490== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   52.50%  647.96us         1  647.96us  647.96us  647.96us  _ZN3cub17CUB_300100_SM_7506detail9transform16transform_kernelINS2_10policy_hubILb1EN4cuda3std3__45tupleIJN6thrust23THRUST_300100_SM_750_NS6detail15normal_iteratorINSA_10device_ptrIiEEEEEEEE10policy1000Ei15evaluateFunctorSF_JPiEEEvT0_iT1_T2_DpNS2_10kernel_argIT3_EE\n",
            "                   23.76%  293.18us         3  97.727us  2.6560us  147.26us  void cub::CUB_300100_SM_750::detail::for_each::static_kernel<cub::CUB_300100_SM_750::detail::for_each::policy_hub_t::policy_500_t, unsigned long, thrust::THRUST_300100_SM_750_NS::cuda_cub::__uninitialized_fill::functor<thrust::THRUST_300100_SM_750_NS::device_ptr<int>, int>>(unsigned long, int)\n",
            "                   11.83%  146.05us         1  146.05us  146.05us  146.05us  void cub::CUB_300100_SM_750::detail::for_each::static_kernel<cub::CUB_300100_SM_750::detail::for_each::policy_hub_t::policy_500_t, long, thrust::THRUST_300100_SM_750_NS::cuda_cub::__tabulate::functor<thrust::THRUST_300100_SM_750_NS::detail::normal_iterator<thrust::THRUST_300100_SM_750_NS::device_ptr<int>>, thrust::THRUST_300100_SM_750_NS::system::detail::generic::detail::compute_sequence_value<int, void>, long>>(long, int)\n",
            "                   11.30%  139.42us         1  139.42us  139.42us  139.42us  void cub::CUB_300100_SM_750::detail::reduce::DeviceReduceKernel<cub::CUB_300100_SM_750::detail::reduce::policy_hub<int, unsigned int, cuda::__4::maximum<int>>::Policy1000, thrust::THRUST_300100_SM_750_NS::detail::normal_iterator<thrust::THRUST_300100_SM_750_NS::device_ptr<int>>, unsigned int, cuda::__4::maximum<int>, int, cuda::std::__4::__identity>(unsigned int, cub::CUB_300100_SM_750::detail::reduce::policy_hub<int, unsigned int, cuda::__4::maximum<int>>::Policy1000*, int, cub::CUB_300100_SM_750::GridEvenShare<cub::CUB_300100_SM_750::detail::reduce::policy_hub<int, unsigned int, cuda::__4::maximum<int>>::Policy1000*>, cuda::__4::maximum<int>, int)\n",
            "                    0.38%  4.7360us         1  4.7360us  4.7360us  4.7360us  void cub::CUB_300100_SM_750::detail::reduce::DeviceReduceSingleTileKernel<cub::CUB_300100_SM_750::detail::reduce::policy_hub<int, unsigned int, cuda::__4::maximum<int>>::Policy1000, int*, int*, int, cuda::__4::maximum<int>, int, int, cuda::std::__4::__identity>(unsigned int, int, cuda::__4::maximum<int>, cub::CUB_300100_SM_750::detail::reduce::policy_hub<int, unsigned int, cuda::__4::maximum<int>>::Policy1000, int*, int)\n",
            "                    0.17%  2.1440us         1  2.1440us  2.1440us  2.1440us  [CUDA memcpy DtoH]\n",
            "                    0.05%     640ns         1     640ns     640ns     640ns  [CUDA memcpy HtoD]\n",
            "      API calls:   97.21%  166.44ms         4  41.609ms  9.6980us  166.16ms  cudaMalloc\n",
            "                    1.33%  2.2756ms         4  568.90us  7.6780us  1.1031ms  cudaFree\n",
            "                    0.72%  1.2390ms         8  154.87us  1.8530us  650.85us  cudaStreamSynchronize\n",
            "                    0.54%  919.38us         1  919.38us  919.38us  919.38us  cudaFuncGetAttributes\n",
            "                    0.10%  163.39us       114  1.4330us     112ns  71.847us  cuDeviceGetAttribute\n",
            "                    0.06%  99.075us         7  14.153us  6.6130us  33.072us  cudaLaunchKernel\n",
            "                    0.02%  31.082us         2  15.541us  9.9340us  21.148us  cudaMemcpyAsync\n",
            "                    0.01%  15.030us         1  15.030us  15.030us  15.030us  cuDeviceGetName\n",
            "                    0.01%  11.993us         3  3.9970us     546ns  9.1640us  cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags\n",
            "                    0.00%  7.8810us        75     105ns      81ns     473ns  cudaGetLastError\n",
            "                    0.00%  6.4540us         1  6.4540us  6.4540us  6.4540us  cuDeviceGetPCIBusId\n",
            "                    0.00%  5.5710us        11     506ns     203ns  1.2790us  cudaGetDevice\n",
            "                    0.00%  1.9260us         3     642ns     256ns  1.2860us  cudaDeviceGetAttribute\n",
            "                    0.00%  1.2290us         9     136ns      85ns     209ns  cudaPeekAtLastError\n",
            "                    0.00%  1.0410us         3     347ns     136ns     717ns  cuDeviceGetCount\n",
            "                    0.00%     637ns         2     318ns     120ns     517ns  cuDeviceGet\n",
            "                    0.00%     583ns         1     583ns     583ns     583ns  cuDeviceTotalMem\n",
            "                    0.00%     398ns         1     398ns     398ns     398ns  cuModuleGetLoadingMode\n",
            "                    0.00%     321ns         1     321ns     321ns     321ns  cudaGetDeviceCount\n",
            "                    0.00%     273ns         1     273ns     273ns     273ns  cuDeviceGetUuid\n",
            "\n",
            "==4490== NVTX result:\n",
            "==4490==   Thread \"<unnamed>\" (id = 10891264)\n",
            "==4490==     Domain \"CCCL\"\n",
            "==4490==       Range \"cub::DeviceFor::Bulk\"\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            "          Range:  100.00%  1.0330ms         4  258.26us  14.932us  971.09us  cub::DeviceFor::Bulk\n",
            " GPU activities:   66.75%  293.18us         3  97.727us  2.6560us  147.26us  void cub::CUB_300100_SM_750::detail::for_each::static_kernel<cub::CUB_300100_SM_750::detail::for_each::policy_hub_t::policy_500_t, unsigned long, thrust::THRUST_300100_SM_750_NS::cuda_cub::__uninitialized_fill::functor<thrust::THRUST_300100_SM_750_NS::device_ptr<int>, int>>(unsigned long, int)\n",
            "                   33.25%  146.05us         1  146.05us  146.05us  146.05us  void cub::CUB_300100_SM_750::detail::for_each::static_kernel<cub::CUB_300100_SM_750::detail::for_each::policy_hub_t::policy_500_t, long, thrust::THRUST_300100_SM_750_NS::cuda_cub::__tabulate::functor<thrust::THRUST_300100_SM_750_NS::detail::normal_iterator<thrust::THRUST_300100_SM_750_NS::device_ptr<int>>, thrust::THRUST_300100_SM_750_NS::system::detail::generic::detail::compute_sequence_value<int, void>, long>>(long, int)\n",
            "      API calls:  100.00%  76.387us         4  19.096us  10.794us  33.072us  cudaLaunchKernel\n",
            "\n",
            "==4490==       Range \"cub::DeviceReduce::Reduce\"\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            "          Range:  100.00%  24.236us         1  24.236us  24.236us  24.236us  cub::DeviceReduce::Reduce\n",
            " GPU activities:   96.71%  139.42us         1  139.42us  139.42us  139.42us  void cub::CUB_300100_SM_750::detail::reduce::DeviceReduceKernel<cub::CUB_300100_SM_750::detail::reduce::policy_hub<int, unsigned int, cuda::__4::maximum<int>>::Policy1000, thrust::THRUST_300100_SM_750_NS::detail::normal_iterator<thrust::THRUST_300100_SM_750_NS::device_ptr<int>>, unsigned int, cuda::__4::maximum<int>, int, cuda::std::__4::__identity>(unsigned int, cub::CUB_300100_SM_750::detail::reduce::policy_hub<int, unsigned int, cuda::__4::maximum<int>>::Policy1000*, int, cub::CUB_300100_SM_750::GridEvenShare<cub::CUB_300100_SM_750::detail::reduce::policy_hub<int, unsigned int, cuda::__4::maximum<int>>::Policy1000*>, cuda::__4::maximum<int>, int)\n",
            "                    3.29%  4.7360us         1  4.7360us  4.7360us  4.7360us  void cub::CUB_300100_SM_750::detail::reduce::DeviceReduceSingleTileKernel<cub::CUB_300100_SM_750::detail::reduce::policy_hub<int, unsigned int, cuda::__4::maximum<int>>::Policy1000, int*, int*, int, cuda::__4::maximum<int>, int, int, cuda::std::__4::__identity>(unsigned int, int, cuda::__4::maximum<int>, cub::CUB_300100_SM_750::detail::reduce::policy_hub<int, unsigned int, cuda::__4::maximum<int>>::Policy1000, int*, int)\n",
            "      API calls:  100.00%  15.934us         2  7.9670us  6.6130us  9.3210us  cudaLaunchKernel\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./partition_thrust < test_with_no_solution_29.txt"
      ],
      "metadata": {
        "id": "c7_R2PFOoyya",
        "outputId": "446c213d-975b-4f3f-99da-57e6bf85d071",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==4502== NVPROF is profiling process 4502, command: ./partition_thrust\n",
            "Number of subsets to evaluate is : 268435456\n",
            "This instance does not have a solution. \n",
            "==4502== Profiling application: ./partition_thrust\n",
            "==4502== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   56.46%  24.083ms         1  24.083ms  24.083ms  24.083ms  _ZN3cub17CUB_300100_SM_7506detail9transform16transform_kernelINS2_10policy_hubILb1EN4cuda3std3__45tupleIJN6thrust23THRUST_300100_SM_750_NS6detail15normal_iteratorINSA_10device_ptrIiEEEEEEEE10policy1000Ei15evaluateFunctorSF_JPiEEEvT0_iT1_T2_DpNS2_10kernel_argIT3_EE\n",
            "                   21.73%  9.2689ms         3  3.0896ms  2.7200us  4.6358ms  void cub::CUB_300100_SM_750::detail::for_each::static_kernel<cub::CUB_300100_SM_750::detail::for_each::policy_hub_t::policy_500_t, unsigned long, thrust::THRUST_300100_SM_750_NS::cuda_cub::__uninitialized_fill::functor<thrust::THRUST_300100_SM_750_NS::device_ptr<int>, int>>(unsigned long, int)\n",
            "                   10.91%  4.6545ms         1  4.6545ms  4.6545ms  4.6545ms  void cub::CUB_300100_SM_750::detail::reduce::DeviceReduceKernel<cub::CUB_300100_SM_750::detail::reduce::policy_hub<int, unsigned int, cuda::__4::maximum<int>>::Policy1000, thrust::THRUST_300100_SM_750_NS::detail::normal_iterator<thrust::THRUST_300100_SM_750_NS::device_ptr<int>>, unsigned int, cuda::__4::maximum<int>, int, cuda::std::__4::__identity>(unsigned int, cub::CUB_300100_SM_750::detail::reduce::policy_hub<int, unsigned int, cuda::__4::maximum<int>>::Policy1000*, int, cub::CUB_300100_SM_750::GridEvenShare<cub::CUB_300100_SM_750::detail::reduce::policy_hub<int, unsigned int, cuda::__4::maximum<int>>::Policy1000*>, cuda::__4::maximum<int>, int)\n",
            "                   10.87%  4.6376ms         1  4.6376ms  4.6376ms  4.6376ms  void cub::CUB_300100_SM_750::detail::for_each::static_kernel<cub::CUB_300100_SM_750::detail::for_each::policy_hub_t::policy_500_t, long, thrust::THRUST_300100_SM_750_NS::cuda_cub::__tabulate::functor<thrust::THRUST_300100_SM_750_NS::detail::normal_iterator<thrust::THRUST_300100_SM_750_NS::device_ptr<int>>, thrust::THRUST_300100_SM_750_NS::system::detail::generic::detail::compute_sequence_value<int, void>, long>>(long, int)\n",
            "                    0.01%  4.9910us         1  4.9910us  4.9910us  4.9910us  void cub::CUB_300100_SM_750::detail::reduce::DeviceReduceSingleTileKernel<cub::CUB_300100_SM_750::detail::reduce::policy_hub<int, unsigned int, cuda::__4::maximum<int>>::Policy1000, int*, int*, int, cuda::__4::maximum<int>, int, int, cuda::std::__4::__identity>(unsigned int, int, cuda::__4::maximum<int>, cub::CUB_300100_SM_750::detail::reduce::policy_hub<int, unsigned int, cuda::__4::maximum<int>>::Policy1000, int*, int)\n",
            "                    0.01%  3.2000us         1  3.2000us  3.2000us  3.2000us  [CUDA memcpy DtoH]\n",
            "                    0.00%     704ns         1     704ns     704ns     704ns  [CUDA memcpy HtoD]\n",
            "      API calls:   76.90%  159.02ms         4  39.755ms  11.137us  158.64ms  cudaMalloc\n",
            "                   20.64%  42.671ms         8  5.3339ms  2.2430us  24.090ms  cudaStreamSynchronize\n",
            "                    1.85%  3.8336ms         4  958.39us  9.3960us  2.6022ms  cudaFree\n",
            "                    0.44%  912.07us         1  912.07us  912.07us  912.07us  cudaFuncGetAttributes\n",
            "                    0.06%  133.24us       114  1.1680us     108ns  54.375us  cuDeviceGetAttribute\n",
            "                    0.06%  115.26us         7  16.466us  7.6910us  30.263us  cudaLaunchKernel\n",
            "                    0.02%  34.335us         2  17.167us  9.5640us  24.771us  cudaMemcpyAsync\n",
            "                    0.01%  16.716us         3  5.5720us     674ns  10.431us  cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags\n",
            "                    0.01%  10.879us         1  10.879us  10.879us  10.879us  cuDeviceGetName\n",
            "                    0.00%  8.6830us        75     115ns      81ns     579ns  cudaGetLastError\n",
            "                    0.00%  7.3100us        11     664ns     233ns  1.3870us  cudaGetDevice\n",
            "                    0.00%  5.9960us         1  5.9960us  5.9960us  5.9960us  cuDeviceGetPCIBusId\n",
            "                    0.00%  3.2060us         3  1.0680us     303ns  1.7340us  cudaDeviceGetAttribute\n",
            "                    0.00%  1.2590us         9     139ns     102ns     181ns  cudaPeekAtLastError\n",
            "                    0.00%  1.2080us         3     402ns     131ns     842ns  cuDeviceGetCount\n",
            "                    0.00%     914ns         2     457ns     166ns     748ns  cuDeviceGet\n",
            "                    0.00%     664ns         1     664ns     664ns     664ns  cuDeviceTotalMem\n",
            "                    0.00%     560ns         1     560ns     560ns     560ns  cuModuleGetLoadingMode\n",
            "                    0.00%     307ns         1     307ns     307ns     307ns  cudaGetDeviceCount\n",
            "                    0.00%     259ns         1     259ns     259ns     259ns  cuDeviceGetUuid\n",
            "\n",
            "==4502== NVTX result:\n",
            "==4502==   Thread \"<unnamed>\" (id = 4210921472)\n",
            "==4502==     Domain \"CCCL\"\n",
            "==4502==       Range \"cub::DeviceFor::Bulk\"\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            "          Range:  100.00%  1.0269ms         4  256.72us  19.130us  960.44us  cub::DeviceFor::Bulk\n",
            " GPU activities:   66.65%  9.2689ms         3  3.0896ms  2.7200us  4.6358ms  void cub::CUB_300100_SM_750::detail::for_each::static_kernel<cub::CUB_300100_SM_750::detail::for_each::policy_hub_t::policy_500_t, unsigned long, thrust::THRUST_300100_SM_750_NS::cuda_cub::__uninitialized_fill::functor<thrust::THRUST_300100_SM_750_NS::device_ptr<int>, int>>(unsigned long, int)\n",
            "                   33.35%  4.6376ms         1  4.6376ms  4.6376ms  4.6376ms  void cub::CUB_300100_SM_750::detail::for_each::static_kernel<cub::CUB_300100_SM_750::detail::for_each::policy_hub_t::policy_500_t, long, thrust::THRUST_300100_SM_750_NS::cuda_cub::__tabulate::functor<thrust::THRUST_300100_SM_750_NS::detail::normal_iterator<thrust::THRUST_300100_SM_750_NS::device_ptr<int>>, thrust::THRUST_300100_SM_750_NS::system::detail::generic::detail::compute_sequence_value<int, void>, long>>(long, int)\n",
            "      API calls:  100.00%  77.972us         4  19.493us  14.155us  30.263us  cudaLaunchKernel\n",
            "\n",
            "==4502==       Range \"cub::DeviceReduce::Reduce\"\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            "          Range:  100.00%  36.696us         1  36.696us  36.696us  36.696us  cub::DeviceReduce::Reduce\n",
            " GPU activities:   99.89%  4.6545ms         1  4.6545ms  4.6545ms  4.6545ms  void cub::CUB_300100_SM_750::detail::reduce::DeviceReduceKernel<cub::CUB_300100_SM_750::detail::reduce::policy_hub<int, unsigned int, cuda::__4::maximum<int>>::Policy1000, thrust::THRUST_300100_SM_750_NS::detail::normal_iterator<thrust::THRUST_300100_SM_750_NS::device_ptr<int>>, unsigned int, cuda::__4::maximum<int>, int, cuda::std::__4::__identity>(unsigned int, cub::CUB_300100_SM_750::detail::reduce::policy_hub<int, unsigned int, cuda::__4::maximum<int>>::Policy1000*, int, cub::CUB_300100_SM_750::GridEvenShare<cub::CUB_300100_SM_750::detail::reduce::policy_hub<int, unsigned int, cuda::__4::maximum<int>>::Policy1000*>, cuda::__4::maximum<int>, int)\n",
            "                    0.11%  4.9910us         1  4.9910us  4.9910us  4.9910us  void cub::CUB_300100_SM_750::detail::reduce::DeviceReduceSingleTileKernel<cub::CUB_300100_SM_750::detail::reduce::policy_hub<int, unsigned int, cuda::__4::maximum<int>>::Policy1000, int*, int*, int, cuda::__4::maximum<int>, int, int, cuda::std::__4::__identity>(unsigned int, int, cuda::__4::maximum<int>, cub::CUB_300100_SM_750::detail::reduce::policy_hub<int, unsigned int, cuda::__4::maximum<int>>::Policy1000, int*, int)\n",
            "      API calls:  100.00%  26.496us         2  13.248us  7.6910us  18.805us  cudaLaunchKernel\n",
            "\n"
          ]
        }
      ]
    }
  ]
}